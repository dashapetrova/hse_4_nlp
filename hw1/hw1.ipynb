{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание задания:**\n",
    "\n",
    "1.Подготовить мини-корпус (4-5 текстов или до 10 тысяч токенов) с разметкой ключевых слов.\n",
    "Желательно указать источник корпуса и описать, в каком виде там были представлены ключевые слова.\n",
    "\n",
    "2.Разметить ключевые слова самостоятельно. Оценить пересечение с имеющейся разметкой.\n",
    "\n",
    "3.Применить к этому корпусу 3 метода извлечения ключевых слов на выбор (RAKE, TextRank, tf*idf, OKAPI BM25).\n",
    "\n",
    "4.Оценить точность, полноту, F-меру выбранных методов относительно имеющейся разметки.\n",
    "\n",
    "5.Описать ошибки автоматического выделения ключевых слов (что выделяется лишнее, что не выделяется); предложить свои методы решения этих проблем.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Подготовка корпуса**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты 4 статей взяты с сайта http://sci-article.ru/gryps.php?i=lingvistika.\n",
    "Ключевые слова в данных статьях указаны отдельно после аннотаций. Я скопировала их как строки, а потом создала массив массивов слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu_words = ['эмоционально-оценочные коммуникемы; национально-культурная специфика; коммуникативное поведение; восприятие речи',\\\n",
    "             'лексика со значением «медицинский работник»; тематическая группа; исторический период; английский язык',\\\n",
    "             'информационно-коммуникационные технологии; социальные сети; дидактические свойства; английский язык; обучение иностранным языкам; изучение иностранных языков',\\\n",
    "             'звукоподражания; крики птиц; ассоциативные связи']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clues_orig = []\n",
    "for i in clu_words:\n",
    "    new = i.split('; ')\n",
    "    clues_orig.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['эмоционально-оценочные коммуникемы', 'национально-культурная специфика', 'коммуникативное поведение', 'восприятие речи']\n",
      "['лексика со значением «медицинский работник»', 'тематическая группа', 'исторический период', 'английский язык']\n",
      "['информационно-коммуникационные технологии', 'социальные сети', 'дидактические свойства', 'английский язык', 'обучение иностранным языкам', 'изучение иностранных языков']\n",
      "['звукоподражания', 'крики птиц', 'ассоциативные связи']\n"
     ]
    }
   ],
   "source": [
    "for i in clues_orig:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее создаю массив текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in range(1,5):\n",
    "    name = f'text_{i}.txt'\n",
    "    file = open(name, 'r', encoding = 'utf-8')\n",
    "    text = file.read()\n",
    "    texts.append(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmas = [m.parse(t)[0].normal_form for t in tokens] #0 - первый разбор\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем ключевые слова. Это понадобится позже при оценивании метрик, чтобы такие примеры, как 'социальная сеть' и 'социальные сети', считались один и тем же ключевым словом, а не разными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_t = []\n",
    "for i in clues_orig:\n",
    "    clues = []\n",
    "    for j in i:\n",
    "        clu_tok = ' '.join(normalize(j))\n",
    "        clues.append(clu_tok)\n",
    "    clus_t.append(clues)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['эмоционально оценочный коммуникем',\n",
       "  'национальный культурный специфика',\n",
       "  'коммуникативный поведение',\n",
       "  'восприятие речь'],\n",
       " ['лексика с значение медицинский работник',\n",
       "  'тематический группа',\n",
       "  'исторический период',\n",
       "  'английский язык'],\n",
       " ['информационно коммуникационный технология',\n",
       "  'социальный сеть',\n",
       "  'дидактический свойство',\n",
       "  'английский язык',\n",
       "  'обучение иностранный язык',\n",
       "  'изучение иностранный язык'],\n",
       " ['звукоподражание', 'крик птица', 'ассоциативный связь']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Самостоятельная разметка ключевых слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я выделила следующие ключевые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clu_words_1 = ['эмоционально-оценочные коммуникемы',\\\n",
    "               'коммуникативное поведение']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clu_words_2 = ['тематическая группа \"медицинский работник\"',\\\n",
    "               'английский словарь']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clu_words_3 = ['социальная сеть','обучение английскому языку',\\\n",
    "               'дидактические свойства']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clu_words_4 = ['звукоподражательные глаголы','ассоциативные связи']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clues = []\n",
    "my_clues.append(my_clu_words_1)\n",
    "my_clues.append(my_clu_words_2)\n",
    "my_clues.append(my_clu_words_3)\n",
    "my_clues.append(my_clu_words_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем и их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clus_t = []\n",
    "for i in my_clues:\n",
    "    clues = []\n",
    "    for j in i:\n",
    "        clu_tok = ' '.join(normalize(j))\n",
    "        clues.append(clu_tok)\n",
    "    my_clus_t.append(clues)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эмоционально оценочный коммуникем', 'коммуникативный поведение']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clus_t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди различий можно отметить то, что у меня некоторые ключевые слова более узкие, чем в статьях. Например, \"звукоподражательные глаголы\", а не \"звукоподражание\", или \"обучение английскому языку\" вместо \"обучение иностранным языкам\". Также какая-то пара ключевых сочетаний может быть у меня объединена в одно, например, \"тематическая группа «медицинский работник»\" вместо \"лексика со значением «медицинский работник»\" и \"тематическая группа\". В остальном выделенные ключевые слова совпадают, за тем исключением, что я в принципе выделила меньше слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3&4. Применение трёх автоматических методов и их оценка**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь использовать автоматические методы извлечения ключевых слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Дарья\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for token in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(token)[0].normal_form\n",
    "        )\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in texts:\n",
    "    result = rake.run(normalize_text(i), maxWords=3, minFrequency=2)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('эмоционально-оценочный коммуникем', 10.11111111111111),\n",
       " ('эмоционально-оценочный коммуникть', 10.0),\n",
       " ('рассмотреть данный положение', 8.2),\n",
       " ('героиня произведение дж', 8.166666666666666),\n",
       " ('героиня произведение', 5.166666666666666),\n",
       " ('герой произведение', 4.833333333333334),\n",
       " ('said leclare', 4.333333333333334),\n",
       " ('kinsella « i', 4.222222222222222),\n",
       " ('русский язык', 4.166666666666666),\n",
       " ('во-первых', 4.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in results:\n",
    "    mas = []\n",
    "    for j in i:\n",
    "        mas.append(j[0])\n",
    "    test_res.append(mas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эмоционально-оценочный коммуникем',\n",
       " 'эмоционально-оценочный коммуникть',\n",
       " 'рассмотреть данный положение',\n",
       " 'героиня произведение дж',\n",
       " 'героиня произведение',\n",
       " 'герой произведение',\n",
       " 'said leclare',\n",
       " 'kinsella « i',\n",
       " 'русский язык',\n",
       " 'во-первых']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr_test(true, test):\n",
    "    a = b = c = 0\n",
    "    \n",
    "    for i in test:\n",
    "        if i in true:\n",
    "            a += 1 #выданные релевантные результаты\n",
    "        else:\n",
    "            b += 1 #выданные нерелевантные результаты\n",
    "            \n",
    "    for i in true:\n",
    "        if i not in test:\n",
    "            c += 1 #невыданные релевантные результаты\n",
    "            \n",
    "    if (a+b) != 0:\n",
    "        p = a/(a+b) #precision\n",
    "    else:\n",
    "        p = 0\n",
    "        \n",
    "    if (a+c) != 0:\n",
    "        r = a/(a+c) #recall\n",
    "    else:\n",
    "        r = 0\n",
    "    \n",
    "    if (p+r) != 0:\n",
    "        f1 = 2*(p*r)/(r+p) #f1-score\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return [p, r, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем точность, полноту и f1-score для оригинальных и полученных метрикой ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.034482758620689655, 0.5, 0.06451612903225806]\n",
      "[0.125, 0.5, 0.2]\n",
      "[0.03125, 0.6666666666666666, 0.05970149253731343]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(clus_t[i], test_res[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем точность, полноту и f1-score для выделенных мною и полученных метрикой ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.08333333333333333, 0.6666666666666666, 0.14814814814814814]\n",
      "[0.015625, 0.5, 0.030303030303030304]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(my_clus_t[i], test_res[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords as kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = []\n",
    "for i in texts:\n",
    "    result = kw(normalize_text(i), pos_filter=[], scores=True)\n",
    "    results_2.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем из результатов стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results_2 = []\n",
    "for i in results_2:\n",
    "    mas = []\n",
    "    for j in i:\n",
    "        if j[0] not in stop:\n",
    "            mas.append(j)\n",
    "    new_results_2.append(mas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('свои', 0.19724061799023707),\n",
       " ('эмоционально коммуникем', 0.16961226216496567),\n",
       " ('единица', 0.15464561293777837),\n",
       " ('являться', 0.12410964662018299),\n",
       " ('речевои', 0.1188198023462976),\n",
       " ('русскии язык', 0.11589643091473692),\n",
       " ('которыи', 0.11072540229112474),\n",
       " ('эмоциональныи', 0.10753684815200491),\n",
       " ('дать', 0.10624129530053349),\n",
       " ('ситуация', 0.10106087790200315)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results_2[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_2 = []\n",
    "for i in new_results_2:\n",
    "    mas = []\n",
    "    for j in i:\n",
    "        mas.append(j[0])\n",
    "    test_res_2.append(mas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['свои',\n",
       " 'эмоционально коммуникем',\n",
       " 'единица',\n",
       " 'являться',\n",
       " 'речевои',\n",
       " 'русскии язык',\n",
       " 'которыи',\n",
       " 'эмоциональныи',\n",
       " 'дать',\n",
       " 'ситуация']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res_2[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оценим метрику, опять сравним оригинальные и мои ключевые слова с теми, что выдал TestRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.01639344262295082, 0.6666666666666666, 0.032]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(clus_t[i], test_res_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(my_clus_t[i], test_res_2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что результаты здесь гораздо хуже, чем у Rake, даже если убрать стоп-слова, которые присутствовали среди результатов изначально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tok = []\n",
    "for i in texts:\n",
    "    new_t = normalize(i)\n",
    "    s = ' '.join(new_t)\n",
    "    texts_tok.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(texts_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = np.array(tfidf_vectorizer.get_feature_names())\n",
    "matrix = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01191928 0.         ... 0.         0.         0.        ]\n",
      "[0.0388579 0.        0.        ... 0.        0.        0.       ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.         0.         0.01329274 ... 0.02658548 0.01329274 0.01329274]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1085, 2351, 1539, 2327, 1316, 1886,  865, 1906, 1312, 2371],\n",
       "       dtype=int64),\n",
       " array([1164,  333, 1155, 1205, 1154,  137, 1204, 1157, 1646,  661],\n",
       "       dtype=int64),\n",
       " array([1951, 2032, 1425, 1265, 2371, 1830,  504, 1639, 1002, 2327],\n",
       "       dtype=int64),\n",
       " array([1798, 1125, 1112, 2371,  930,  965,  933,  710,  934,  244],\n",
       "       dtype=int64)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = []\n",
    "for row in matrix:\n",
    "    print(row)\n",
    "    idx_sort = np.argsort(list(row))\n",
    "    idx.append(idx_sort[::-1][:10]) #будем брать первые десять слов с наибольшим tf-idf score\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3 = []\n",
    "for i in idx:\n",
    "    res = []\n",
    "    for j in i:\n",
    "        res.append(all_words[j])\n",
    "    results_3.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['коммуникем',\n",
       " 'эмоционально',\n",
       " 'оценочный',\n",
       " 'что',\n",
       " 'не',\n",
       " 'речь',\n",
       " 'единица',\n",
       " 'русский',\n",
       " 'национальный',\n",
       " 'язык']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.1, 0.3333333333333333, 0.15384615384615383]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(clus_t[i], results_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n",
      "[0.0, 0.0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(my_clus_t[i], results_3[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь результаты тоже плохие. В данном случае это связано с тем, что благодаря tf-idf матрице мы узнаем релевантные для текстов слова, но не их сочетания. Чтобы немного сгладить картину, можно разбить ключевые слова по токенам и посмотреть попадания чисто по ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_words = []\n",
    "for i in clus_t:\n",
    "    text_words = []\n",
    "    for j in i:\n",
    "        words = j.split()\n",
    "        for q in words:\n",
    "            text_words.append(q)\n",
    "    all_text_words.append(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эмоционально',\n",
       " 'оценочный',\n",
       " 'коммуникем',\n",
       " 'национальный',\n",
       " 'культурный',\n",
       " 'специфика',\n",
       " 'коммуникативный',\n",
       " 'поведение',\n",
       " 'восприятие',\n",
       " 'речь']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_my_text_words = []\n",
    "for i in my_clus_t:\n",
    "    text_words = []\n",
    "    for j in i:\n",
    "        words = j.split()\n",
    "        for q in words:\n",
    "            text_words.append(q)\n",
    "    all_my_text_words.append(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эмоционально', 'оценочный', 'коммуникем', 'коммуникативный', 'поведение']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_my_text_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5]\n",
      "[0.1, 0.09090909090909091, 0.09523809523809525]\n",
      "[0.5, 0.38461538461538464, 0.4347826086956522]\n",
      "[0.3, 0.6, 0.4]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(all_text_words[i], results_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.6, 0.4]\n",
      "[0.1, 0.16666666666666666, 0.125]\n",
      "[0.5, 0.7142857142857143, 0.588235294117647]\n",
      "[0.1, 0.25, 0.14285714285714288]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(metr_test(all_my_text_words[i], results_3[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь стало лучше, хотя немного некорректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Описание проблем и их возможное решение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из проблем, которая ухудшила результаты всех метрик, это не самая корректная нормализация ключевых слов, которые были выделены в оригинальном тексте и которые я разметила вручную. Минус нормализации заключался в том, что из словосочетаний пропадали также и необходимые дефисы, которые однако оставались при токенизации у разных метрик, например, \"эмоционально-оценочный коммуникем\". Подобным образом вполне могли бы токенизироваться иначе и какие-нибудь другие необычные выражения. Чтобы решить эту проблему, стоит уделить чуть большее внимания функции токенизации, учтя в ней такие случаи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маленький минус TextRank заключался также в том, что он не учитывал стоп-слова. Но их можно убрать уже из самих результатов, как и было проделанно в этой работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недочет метрики с tf-idf был уже описан выше. Я попробовала исправить его не самым изящным способом. Для более правильного результата, следовало бы, наоборот, не разбить ключевые слова на токены, а посчитать tf-idf score, например, для биграмм и триграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге, можно сказать, что TextRank справился хуже всех, Rake позакал неплохие результаты, а tf-idf был лучшим, хотя работал только со словами, а не словосочетаниями."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
